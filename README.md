# Crime Analysis in Chicago City

## Overview
This project, developed by Sai Sanwariya Narayan, focuses on analyzing crime data in Chicago using PySpark and various Python libraries. The analysis includes data cleaning, aggregation, visualization, and machine learning to predict crime trends and patterns. The project utilizes a range of tools like PySpark, Pandas, NumPy, Plotly, Seaborn, GeoPandas, and scikit-learn.

## Program Functionality
1. **Data Loading and Cleaning**: Importing multiple years of crime data, merging, and cleaning to remove null values.
2. **Data Aggregation**: Using MapReduce for aggregating data based on crime type, community areas, and time.
3. **Visualization**: Generating bar graphs, pie charts, tree maps, and heat maps to visualize crime data effectively.
4. **Machine Learning**: Implementing and evaluating models like Decision Tree and KMeans for predicting crime patterns.
5. **Clustering Analysis**: Using DBSCAN for spatial clustering of crime data.
6. **Interactive Graphs**: Creating interactive time-series graphs for better analysis.
7. **MapReduce Implementations**: Employed for various analytical purposes such as crime counts by hour and arrest counts by crime type.


## Notes
- The project requires a Spark environment (PySpark) and several Python libraries like Pandas, Seaborn, Matplotlib, and scikit-learn.
- Data visualization is a key aspect; Plotly and Seaborn are used extensively for this purpose.
- The machine learning models might require tuning based on the dataset size and nature.
- This README provides a broad overview and might not cover every detail of the implementation. Users are encouraged to delve into the code for a deeper understanding.
